I1204 23:35:09.320742 31619 caffe.cpp:217] Using GPUs 0
I1204 23:35:11.381901 31619 caffe.cpp:222] GPU 0: GeForce GTX TITAN X
I1204 23:35:11.712291 31619 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "examples/mnist/lenet_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I1204 23:35:11.717164 31619 solver.cpp:91] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I1204 23:35:11.717705 31619 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1204 23:35:11.717730 31619 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1204 23:35:11.717854 31619 net.cpp:58] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1204 23:35:11.717970 31619 layer_factory.hpp:77] Creating layer mnist
I1204 23:35:11.718606 31619 net.cpp:100] Creating Layer mnist
I1204 23:35:11.718631 31619 net.cpp:408] mnist -> data
I1204 23:35:11.718727 31619 net.cpp:408] mnist -> label
I1204 23:35:11.720587 31624 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I1204 23:35:11.733371 31619 data_layer.cpp:41] output data size: 64,1,28,28
I1204 23:35:11.734683 31619 net.cpp:150] Setting up mnist
I1204 23:35:11.734719 31619 net.cpp:157] Top shape: 64 1 28 28 (50176)
I1204 23:35:11.734726 31619 net.cpp:157] Top shape: 64 (64)
I1204 23:35:11.734730 31619 net.cpp:165] Memory required for data: 200960
I1204 23:35:11.734742 31619 layer_factory.hpp:77] Creating layer conv1
I1204 23:35:11.734772 31619 net.cpp:100] Creating Layer conv1
I1204 23:35:11.734781 31619 net.cpp:434] conv1 <- data
I1204 23:35:11.734800 31619 net.cpp:408] conv1 -> conv1
I1204 23:35:11.735961 31619 net.cpp:150] Setting up conv1
I1204 23:35:11.735980 31619 net.cpp:157] Top shape: 64 20 24 24 (737280)
I1204 23:35:11.735985 31619 net.cpp:165] Memory required for data: 3150080
I1204 23:35:11.736007 31619 layer_factory.hpp:77] Creating layer pool1
I1204 23:35:11.736024 31619 net.cpp:100] Creating Layer pool1
I1204 23:35:11.736054 31619 net.cpp:434] pool1 <- conv1
I1204 23:35:11.736063 31619 net.cpp:408] pool1 -> pool1
I1204 23:35:11.736125 31619 net.cpp:150] Setting up pool1
I1204 23:35:11.736135 31619 net.cpp:157] Top shape: 64 20 12 12 (184320)
I1204 23:35:11.736138 31619 net.cpp:165] Memory required for data: 3887360
I1204 23:35:11.736142 31619 layer_factory.hpp:77] Creating layer conv2
I1204 23:35:11.736155 31619 net.cpp:100] Creating Layer conv2
I1204 23:35:11.736160 31619 net.cpp:434] conv2 <- pool1
I1204 23:35:11.736171 31619 net.cpp:408] conv2 -> conv2
I1204 23:35:11.736594 31619 net.cpp:150] Setting up conv2
I1204 23:35:11.736608 31619 net.cpp:157] Top shape: 64 50 8 8 (204800)
I1204 23:35:11.736611 31619 net.cpp:165] Memory required for data: 4706560
I1204 23:35:11.736621 31619 layer_factory.hpp:77] Creating layer pool2
I1204 23:35:11.736630 31619 net.cpp:100] Creating Layer pool2
I1204 23:35:11.736635 31619 net.cpp:434] pool2 <- conv2
I1204 23:35:11.736644 31619 net.cpp:408] pool2 -> pool2
I1204 23:35:11.736682 31619 net.cpp:150] Setting up pool2
I1204 23:35:11.736690 31619 net.cpp:157] Top shape: 64 50 4 4 (51200)
I1204 23:35:11.736693 31619 net.cpp:165] Memory required for data: 4911360
I1204 23:35:11.736697 31619 layer_factory.hpp:77] Creating layer ip1
I1204 23:35:11.736712 31619 net.cpp:100] Creating Layer ip1
I1204 23:35:11.736717 31619 net.cpp:434] ip1 <- pool2
I1204 23:35:11.736732 31619 net.cpp:408] ip1 -> ip1
I1204 23:35:11.741176 31619 net.cpp:150] Setting up ip1
I1204 23:35:11.741195 31619 net.cpp:157] Top shape: 64 500 (32000)
I1204 23:35:11.741200 31619 net.cpp:165] Memory required for data: 5039360
I1204 23:35:11.741211 31619 layer_factory.hpp:77] Creating layer relu1
I1204 23:35:11.741221 31619 net.cpp:100] Creating Layer relu1
I1204 23:35:11.741226 31619 net.cpp:434] relu1 <- ip1
I1204 23:35:11.741232 31619 net.cpp:395] relu1 -> ip1 (in-place)
I1204 23:35:11.741252 31619 net.cpp:150] Setting up relu1
I1204 23:35:11.741258 31619 net.cpp:157] Top shape: 64 500 (32000)
I1204 23:35:11.741262 31619 net.cpp:165] Memory required for data: 5167360
I1204 23:35:11.741266 31619 layer_factory.hpp:77] Creating layer ip2
I1204 23:35:11.741277 31619 net.cpp:100] Creating Layer ip2
I1204 23:35:11.741281 31619 net.cpp:434] ip2 <- ip1
I1204 23:35:11.741291 31619 net.cpp:408] ip2 -> ip2
I1204 23:35:11.742166 31619 net.cpp:150] Setting up ip2
I1204 23:35:11.742183 31619 net.cpp:157] Top shape: 64 10 (640)
I1204 23:35:11.742187 31619 net.cpp:165] Memory required for data: 5169920
I1204 23:35:11.742197 31619 layer_factory.hpp:77] Creating layer loss
I1204 23:35:11.742213 31619 net.cpp:100] Creating Layer loss
I1204 23:35:11.742218 31619 net.cpp:434] loss <- ip2
I1204 23:35:11.742224 31619 net.cpp:434] loss <- label
I1204 23:35:11.742233 31619 net.cpp:408] loss -> loss
I1204 23:35:11.742259 31619 layer_factory.hpp:77] Creating layer loss
I1204 23:35:11.742370 31619 net.cpp:150] Setting up loss
I1204 23:35:11.742382 31619 net.cpp:157] Top shape: (1)
I1204 23:35:11.742386 31619 net.cpp:160]     with loss weight 1
I1204 23:35:11.742420 31619 net.cpp:165] Memory required for data: 5169924
I1204 23:35:11.742426 31619 net.cpp:226] loss needs backward computation.
I1204 23:35:11.742431 31619 net.cpp:226] ip2 needs backward computation.
I1204 23:35:11.742435 31619 net.cpp:226] relu1 needs backward computation.
I1204 23:35:11.742439 31619 net.cpp:226] ip1 needs backward computation.
I1204 23:35:11.742442 31619 net.cpp:226] pool2 needs backward computation.
I1204 23:35:11.742446 31619 net.cpp:226] conv2 needs backward computation.
I1204 23:35:11.742450 31619 net.cpp:226] pool1 needs backward computation.
I1204 23:35:11.742455 31619 net.cpp:226] conv1 needs backward computation.
I1204 23:35:11.742458 31619 net.cpp:228] mnist does not need backward computation.
I1204 23:35:11.742462 31619 net.cpp:270] This network produces output loss
I1204 23:35:11.742473 31619 net.cpp:283] Network initialization done.
I1204 23:35:11.742908 31619 solver.cpp:181] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I1204 23:35:11.742961 31619 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1204 23:35:11.743089 31619 net.cpp:58] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1204 23:35:11.743181 31619 layer_factory.hpp:77] Creating layer mnist
I1204 23:35:11.743829 31619 net.cpp:100] Creating Layer mnist
I1204 23:35:11.743863 31619 net.cpp:408] mnist -> data
I1204 23:35:11.743880 31619 net.cpp:408] mnist -> label
I1204 23:35:11.745384 31626 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I1204 23:35:11.745556 31619 data_layer.cpp:41] output data size: 100,1,28,28
I1204 23:35:11.747081 31619 net.cpp:150] Setting up mnist
I1204 23:35:11.747100 31619 net.cpp:157] Top shape: 100 1 28 28 (78400)
I1204 23:35:11.747108 31619 net.cpp:157] Top shape: 100 (100)
I1204 23:35:11.747113 31619 net.cpp:165] Memory required for data: 314000
I1204 23:35:11.747119 31619 layer_factory.hpp:77] Creating layer label_mnist_1_split
I1204 23:35:11.747166 31619 net.cpp:100] Creating Layer label_mnist_1_split
I1204 23:35:11.747174 31619 net.cpp:434] label_mnist_1_split <- label
I1204 23:35:11.747181 31619 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_0
I1204 23:35:11.747210 31619 net.cpp:408] label_mnist_1_split -> label_mnist_1_split_1
I1204 23:35:11.747257 31619 net.cpp:150] Setting up label_mnist_1_split
I1204 23:35:11.747267 31619 net.cpp:157] Top shape: 100 (100)
I1204 23:35:11.747272 31619 net.cpp:157] Top shape: 100 (100)
I1204 23:35:11.747275 31619 net.cpp:165] Memory required for data: 314800
I1204 23:35:11.747280 31619 layer_factory.hpp:77] Creating layer conv1
I1204 23:35:11.747298 31619 net.cpp:100] Creating Layer conv1
I1204 23:35:11.747303 31619 net.cpp:434] conv1 <- data
I1204 23:35:11.747313 31619 net.cpp:408] conv1 -> conv1
I1204 23:35:11.747706 31619 net.cpp:150] Setting up conv1
I1204 23:35:11.747720 31619 net.cpp:157] Top shape: 100 20 24 24 (1152000)
I1204 23:35:11.747725 31619 net.cpp:165] Memory required for data: 4922800
I1204 23:35:11.747736 31619 layer_factory.hpp:77] Creating layer pool1
I1204 23:35:11.747763 31619 net.cpp:100] Creating Layer pool1
I1204 23:35:11.747769 31619 net.cpp:434] pool1 <- conv1
I1204 23:35:11.747776 31619 net.cpp:408] pool1 -> pool1
I1204 23:35:11.747828 31619 net.cpp:150] Setting up pool1
I1204 23:35:11.747838 31619 net.cpp:157] Top shape: 100 20 12 12 (288000)
I1204 23:35:11.747841 31619 net.cpp:165] Memory required for data: 6074800
I1204 23:35:11.747845 31619 layer_factory.hpp:77] Creating layer conv2
I1204 23:35:11.747859 31619 net.cpp:100] Creating Layer conv2
I1204 23:35:11.747864 31619 net.cpp:434] conv2 <- pool1
I1204 23:35:11.747874 31619 net.cpp:408] conv2 -> conv2
I1204 23:35:11.748311 31619 net.cpp:150] Setting up conv2
I1204 23:35:11.748324 31619 net.cpp:157] Top shape: 100 50 8 8 (320000)
I1204 23:35:11.748328 31619 net.cpp:165] Memory required for data: 7354800
I1204 23:35:11.748339 31619 layer_factory.hpp:77] Creating layer pool2
I1204 23:35:11.748347 31619 net.cpp:100] Creating Layer pool2
I1204 23:35:11.748352 31619 net.cpp:434] pool2 <- conv2
I1204 23:35:11.748360 31619 net.cpp:408] pool2 -> pool2
I1204 23:35:11.748404 31619 net.cpp:150] Setting up pool2
I1204 23:35:11.748412 31619 net.cpp:157] Top shape: 100 50 4 4 (80000)
I1204 23:35:11.748416 31619 net.cpp:165] Memory required for data: 7674800
I1204 23:35:11.748420 31619 layer_factory.hpp:77] Creating layer ip1
I1204 23:35:11.748430 31619 net.cpp:100] Creating Layer ip1
I1204 23:35:11.748435 31619 net.cpp:434] ip1 <- pool2
I1204 23:35:11.748441 31619 net.cpp:408] ip1 -> ip1
I1204 23:35:11.752876 31619 net.cpp:150] Setting up ip1
I1204 23:35:11.752903 31619 net.cpp:157] Top shape: 100 500 (50000)
I1204 23:35:11.752908 31619 net.cpp:165] Memory required for data: 7874800
I1204 23:35:11.752920 31619 layer_factory.hpp:77] Creating layer relu1
I1204 23:35:11.752929 31619 net.cpp:100] Creating Layer relu1
I1204 23:35:11.752934 31619 net.cpp:434] relu1 <- ip1
I1204 23:35:11.752952 31619 net.cpp:395] relu1 -> ip1 (in-place)
I1204 23:35:11.752961 31619 net.cpp:150] Setting up relu1
I1204 23:35:11.752969 31619 net.cpp:157] Top shape: 100 500 (50000)
I1204 23:35:11.752980 31619 net.cpp:165] Memory required for data: 8074800
I1204 23:35:11.752990 31619 layer_factory.hpp:77] Creating layer ip2
I1204 23:35:11.753000 31619 net.cpp:100] Creating Layer ip2
I1204 23:35:11.753003 31619 net.cpp:434] ip2 <- ip1
I1204 23:35:11.753013 31619 net.cpp:408] ip2 -> ip2
I1204 23:35:11.753165 31619 net.cpp:150] Setting up ip2
I1204 23:35:11.753185 31619 net.cpp:157] Top shape: 100 10 (1000)
I1204 23:35:11.753188 31619 net.cpp:165] Memory required for data: 8078800
I1204 23:35:11.753196 31619 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I1204 23:35:11.753203 31619 net.cpp:100] Creating Layer ip2_ip2_0_split
I1204 23:35:11.753209 31619 net.cpp:434] ip2_ip2_0_split <- ip2
I1204 23:35:11.753218 31619 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_0
I1204 23:35:11.753227 31619 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_1
I1204 23:35:11.753273 31619 net.cpp:150] Setting up ip2_ip2_0_split
I1204 23:35:11.753280 31619 net.cpp:157] Top shape: 100 10 (1000)
I1204 23:35:11.753285 31619 net.cpp:157] Top shape: 100 10 (1000)
I1204 23:35:11.753300 31619 net.cpp:165] Memory required for data: 8086800
I1204 23:35:11.753304 31619 layer_factory.hpp:77] Creating layer accuracy
I1204 23:35:11.753319 31619 net.cpp:100] Creating Layer accuracy
I1204 23:35:11.753324 31619 net.cpp:434] accuracy <- ip2_ip2_0_split_0
I1204 23:35:11.753329 31619 net.cpp:434] accuracy <- label_mnist_1_split_0
I1204 23:35:11.753340 31619 net.cpp:408] accuracy -> accuracy
I1204 23:35:11.753355 31619 net.cpp:150] Setting up accuracy
I1204 23:35:11.753363 31619 net.cpp:157] Top shape: (1)
I1204 23:35:11.753367 31619 net.cpp:165] Memory required for data: 8086804
I1204 23:35:11.753389 31619 layer_factory.hpp:77] Creating layer loss
I1204 23:35:11.753401 31619 net.cpp:100] Creating Layer loss
I1204 23:35:11.753408 31619 net.cpp:434] loss <- ip2_ip2_0_split_1
I1204 23:35:11.753422 31619 net.cpp:434] loss <- label_mnist_1_split_1
I1204 23:35:11.753451 31619 net.cpp:408] loss -> loss
I1204 23:35:11.753463 31619 layer_factory.hpp:77] Creating layer loss
I1204 23:35:11.753568 31619 net.cpp:150] Setting up loss
I1204 23:35:11.753589 31619 net.cpp:157] Top shape: (1)
I1204 23:35:11.753593 31619 net.cpp:160]     with loss weight 1
I1204 23:35:11.753602 31619 net.cpp:165] Memory required for data: 8086808
I1204 23:35:11.753607 31619 net.cpp:226] loss needs backward computation.
I1204 23:35:11.753612 31619 net.cpp:228] accuracy does not need backward computation.
I1204 23:35:11.753618 31619 net.cpp:226] ip2_ip2_0_split needs backward computation.
I1204 23:35:11.753630 31619 net.cpp:226] ip2 needs backward computation.
I1204 23:35:11.753634 31619 net.cpp:226] relu1 needs backward computation.
I1204 23:35:11.753638 31619 net.cpp:226] ip1 needs backward computation.
I1204 23:35:11.753659 31619 net.cpp:226] pool2 needs backward computation.
I1204 23:35:11.753664 31619 net.cpp:226] conv2 needs backward computation.
I1204 23:35:11.753667 31619 net.cpp:226] pool1 needs backward computation.
I1204 23:35:11.753671 31619 net.cpp:226] conv1 needs backward computation.
I1204 23:35:11.753684 31619 net.cpp:228] label_mnist_1_split does not need backward computation.
I1204 23:35:11.753696 31619 net.cpp:228] mnist does not need backward computation.
I1204 23:35:11.753707 31619 net.cpp:270] This network produces output accuracy
I1204 23:35:11.753712 31619 net.cpp:270] This network produces output loss
I1204 23:35:11.753728 31619 net.cpp:283] Network initialization done.
I1204 23:35:11.753785 31619 solver.cpp:60] Solver scaffolding done.
I1204 23:35:11.754079 31619 caffe.cpp:251] Starting Optimization
I1204 23:35:11.754094 31619 solver.cpp:279] Solving LeNet
I1204 23:35:11.754098 31619 solver.cpp:280] Learning Rate Policy: inv
I1204 23:35:11.754586 31619 solver.cpp:337] Iteration 0, Testing net (#0)
I1204 23:35:12.845114 31619 solver.cpp:404]     Test net output #0: accuracy = 0.145
I1204 23:35:12.845140 31619 solver.cpp:404]     Test net output #1: loss = 2.3086 (* 1 = 2.3086 loss)
I1204 23:35:12.855772 31619 solver.cpp:228] Iteration 0, loss = 2.30675
I1204 23:35:12.855792 31619 solver.cpp:244]     Train net output #0: loss = 2.30675 (* 1 = 2.30675 loss)
I1204 23:35:12.855818 31619 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I1204 23:35:14.380888 31619 solver.cpp:228] Iteration 100, loss = 0.19337
I1204 23:35:14.380928 31619 solver.cpp:244]     Train net output #0: loss = 0.19337 (* 1 = 0.19337 loss)
I1204 23:35:14.380936 31619 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I1204 23:35:15.914414 31619 solver.cpp:228] Iteration 200, loss = 0.149177
I1204 23:35:15.914443 31619 solver.cpp:244]     Train net output #0: loss = 0.149177 (* 1 = 0.149177 loss)
I1204 23:35:15.914449 31619 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I1204 23:35:17.448411 31619 solver.cpp:228] Iteration 300, loss = 0.168159
I1204 23:35:17.448436 31619 solver.cpp:244]     Train net output #0: loss = 0.168159 (* 1 = 0.168159 loss)
I1204 23:35:17.448443 31619 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I1204 23:35:18.983816 31619 solver.cpp:228] Iteration 400, loss = 0.0790428
I1204 23:35:18.983845 31619 solver.cpp:244]     Train net output #0: loss = 0.0790428 (* 1 = 0.0790428 loss)
I1204 23:35:18.983852 31619 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I1204 23:35:20.502192 31619 solver.cpp:337] Iteration 500, Testing net (#0)
I1204 23:35:21.576967 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9707
I1204 23:35:21.576994 31619 solver.cpp:404]     Test net output #1: loss = 0.0918415 (* 1 = 0.0918415 loss)
I1204 23:35:21.586578 31619 solver.cpp:228] Iteration 500, loss = 0.143058
I1204 23:35:21.586597 31619 solver.cpp:244]     Train net output #0: loss = 0.143058 (* 1 = 0.143058 loss)
I1204 23:35:21.586606 31619 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I1204 23:35:23.120981 31619 solver.cpp:228] Iteration 600, loss = 0.0682055
I1204 23:35:23.121002 31619 solver.cpp:244]     Train net output #0: loss = 0.0682055 (* 1 = 0.0682055 loss)
I1204 23:35:23.121031 31619 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I1204 23:35:24.655436 31619 solver.cpp:228] Iteration 700, loss = 0.111084
I1204 23:35:24.655460 31619 solver.cpp:244]     Train net output #0: loss = 0.111084 (* 1 = 0.111084 loss)
I1204 23:35:24.655467 31619 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I1204 23:35:26.191081 31619 solver.cpp:228] Iteration 800, loss = 0.1963
I1204 23:35:26.191123 31619 solver.cpp:244]     Train net output #0: loss = 0.1963 (* 1 = 0.1963 loss)
I1204 23:35:26.191131 31619 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I1204 23:35:27.727426 31619 solver.cpp:228] Iteration 900, loss = 0.207385
I1204 23:35:27.727447 31619 solver.cpp:244]     Train net output #0: loss = 0.207385 (* 1 = 0.207385 loss)
I1204 23:35:27.727453 31619 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I1204 23:35:29.246281 31619 solver.cpp:337] Iteration 1000, Testing net (#0)
I1204 23:35:30.322886 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9829
I1204 23:35:30.322926 31619 solver.cpp:404]     Test net output #1: loss = 0.0558595 (* 1 = 0.0558595 loss)
I1204 23:35:30.332619 31619 solver.cpp:228] Iteration 1000, loss = 0.0856254
I1204 23:35:30.332650 31619 solver.cpp:244]     Train net output #0: loss = 0.0856254 (* 1 = 0.0856254 loss)
I1204 23:35:30.332659 31619 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I1204 23:35:31.869683 31619 solver.cpp:228] Iteration 1100, loss = 0.00831686
I1204 23:35:31.869716 31619 solver.cpp:244]     Train net output #0: loss = 0.00831674 (* 1 = 0.00831674 loss)
I1204 23:35:31.869724 31619 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I1204 23:35:33.403851 31619 solver.cpp:228] Iteration 1200, loss = 0.0235056
I1204 23:35:33.403877 31619 solver.cpp:244]     Train net output #0: loss = 0.0235054 (* 1 = 0.0235054 loss)
I1204 23:35:33.403883 31619 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I1204 23:35:34.938792 31619 solver.cpp:228] Iteration 1300, loss = 0.0179248
I1204 23:35:34.938818 31619 solver.cpp:244]     Train net output #0: loss = 0.0179247 (* 1 = 0.0179247 loss)
I1204 23:35:34.938828 31619 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I1204 23:35:36.473554 31619 solver.cpp:228] Iteration 1400, loss = 0.00815712
I1204 23:35:36.473577 31619 solver.cpp:244]     Train net output #0: loss = 0.00815699 (* 1 = 0.00815699 loss)
I1204 23:35:36.473583 31619 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I1204 23:35:37.993302 31619 solver.cpp:337] Iteration 1500, Testing net (#0)
I1204 23:35:39.071184 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9844
I1204 23:35:39.071223 31619 solver.cpp:404]     Test net output #1: loss = 0.0493341 (* 1 = 0.0493341 loss)
I1204 23:35:39.080904 31619 solver.cpp:228] Iteration 1500, loss = 0.0634561
I1204 23:35:39.080935 31619 solver.cpp:244]     Train net output #0: loss = 0.0634559 (* 1 = 0.0634559 loss)
I1204 23:35:39.080943 31619 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I1204 23:35:40.616505 31619 solver.cpp:228] Iteration 1600, loss = 0.117124
I1204 23:35:40.616597 31619 solver.cpp:244]     Train net output #0: loss = 0.117124 (* 1 = 0.117124 loss)
I1204 23:35:40.616607 31619 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I1204 23:35:42.151897 31619 solver.cpp:228] Iteration 1700, loss = 0.0375801
I1204 23:35:42.151932 31619 solver.cpp:244]     Train net output #0: loss = 0.03758 (* 1 = 0.03758 loss)
I1204 23:35:42.151938 31619 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I1204 23:35:43.688314 31619 solver.cpp:228] Iteration 1800, loss = 0.0242605
I1204 23:35:43.688345 31619 solver.cpp:244]     Train net output #0: loss = 0.0242603 (* 1 = 0.0242603 loss)
I1204 23:35:43.688352 31619 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I1204 23:35:45.224020 31619 solver.cpp:228] Iteration 1900, loss = 0.139724
I1204 23:35:45.224045 31619 solver.cpp:244]     Train net output #0: loss = 0.139724 (* 1 = 0.139724 loss)
I1204 23:35:45.224051 31619 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I1204 23:35:46.745813 31619 solver.cpp:337] Iteration 2000, Testing net (#0)
I1204 23:35:47.826838 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9845
I1204 23:35:47.826863 31619 solver.cpp:404]     Test net output #1: loss = 0.0459125 (* 1 = 0.0459125 loss)
I1204 23:35:47.836179 31619 solver.cpp:228] Iteration 2000, loss = 0.0156196
I1204 23:35:47.836196 31619 solver.cpp:244]     Train net output #0: loss = 0.0156194 (* 1 = 0.0156194 loss)
I1204 23:35:47.836202 31619 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I1204 23:35:49.373598 31619 solver.cpp:228] Iteration 2100, loss = 0.0121133
I1204 23:35:49.373620 31619 solver.cpp:244]     Train net output #0: loss = 0.0121131 (* 1 = 0.0121131 loss)
I1204 23:35:49.373625 31619 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I1204 23:35:50.910078 31619 solver.cpp:228] Iteration 2200, loss = 0.0175449
I1204 23:35:50.910115 31619 solver.cpp:244]     Train net output #0: loss = 0.0175447 (* 1 = 0.0175447 loss)
I1204 23:35:50.910121 31619 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I1204 23:35:52.445219 31619 solver.cpp:228] Iteration 2300, loss = 0.102037
I1204 23:35:52.445250 31619 solver.cpp:244]     Train net output #0: loss = 0.102037 (* 1 = 0.102037 loss)
I1204 23:35:52.445255 31619 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I1204 23:35:53.981781 31619 solver.cpp:228] Iteration 2400, loss = 0.0190689
I1204 23:35:53.981802 31619 solver.cpp:244]     Train net output #0: loss = 0.0190687 (* 1 = 0.0190687 loss)
I1204 23:35:53.981808 31619 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I1204 23:35:55.511147 31619 solver.cpp:337] Iteration 2500, Testing net (#0)
I1204 23:35:56.605856 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9827
I1204 23:35:56.605877 31619 solver.cpp:404]     Test net output #1: loss = 0.0546349 (* 1 = 0.0546349 loss)
I1204 23:35:56.615389 31619 solver.cpp:228] Iteration 2500, loss = 0.0317118
I1204 23:35:56.615406 31619 solver.cpp:244]     Train net output #0: loss = 0.0317117 (* 1 = 0.0317117 loss)
I1204 23:35:56.615413 31619 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I1204 23:35:58.165724 31619 solver.cpp:228] Iteration 2600, loss = 0.0433943
I1204 23:35:58.165776 31619 solver.cpp:244]     Train net output #0: loss = 0.0433941 (* 1 = 0.0433941 loss)
I1204 23:35:58.165782 31619 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I1204 23:35:59.709097 31619 solver.cpp:228] Iteration 2700, loss = 0.0602546
I1204 23:35:59.709142 31619 solver.cpp:244]     Train net output #0: loss = 0.0602544 (* 1 = 0.0602544 loss)
I1204 23:35:59.709151 31619 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I1204 23:36:01.261767 31619 solver.cpp:228] Iteration 2800, loss = 0.00273372
I1204 23:36:01.261807 31619 solver.cpp:244]     Train net output #0: loss = 0.00273352 (* 1 = 0.00273352 loss)
I1204 23:36:01.261816 31619 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I1204 23:36:02.811265 31619 solver.cpp:228] Iteration 2900, loss = 0.0170505
I1204 23:36:02.811309 31619 solver.cpp:244]     Train net output #0: loss = 0.0170503 (* 1 = 0.0170503 loss)
I1204 23:36:02.811344 31619 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I1204 23:36:04.323396 31619 solver.cpp:337] Iteration 3000, Testing net (#0)
I1204 23:36:05.396046 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9882
I1204 23:36:05.396088 31619 solver.cpp:404]     Test net output #1: loss = 0.0376725 (* 1 = 0.0376725 loss)
I1204 23:36:05.406108 31619 solver.cpp:228] Iteration 3000, loss = 0.00824274
I1204 23:36:05.406131 31619 solver.cpp:244]     Train net output #0: loss = 0.00824254 (* 1 = 0.00824254 loss)
I1204 23:36:05.406150 31619 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I1204 23:36:06.954972 31619 solver.cpp:228] Iteration 3100, loss = 0.0264087
I1204 23:36:06.955005 31619 solver.cpp:244]     Train net output #0: loss = 0.0264085 (* 1 = 0.0264085 loss)
I1204 23:36:06.955013 31619 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I1204 23:36:08.504492 31619 solver.cpp:228] Iteration 3200, loss = 0.00842783
I1204 23:36:08.504528 31619 solver.cpp:244]     Train net output #0: loss = 0.00842766 (* 1 = 0.00842766 loss)
I1204 23:36:08.504535 31619 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I1204 23:36:10.051081 31619 solver.cpp:228] Iteration 3300, loss = 0.0116484
I1204 23:36:10.051115 31619 solver.cpp:244]     Train net output #0: loss = 0.0116482 (* 1 = 0.0116482 loss)
I1204 23:36:10.051122 31619 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I1204 23:36:11.597934 31619 solver.cpp:228] Iteration 3400, loss = 0.0123025
I1204 23:36:11.598063 31619 solver.cpp:244]     Train net output #0: loss = 0.0123024 (* 1 = 0.0123024 loss)
I1204 23:36:11.598073 31619 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I1204 23:36:13.130180 31619 solver.cpp:337] Iteration 3500, Testing net (#0)
I1204 23:36:14.225061 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9858
I1204 23:36:14.225088 31619 solver.cpp:404]     Test net output #1: loss = 0.044137 (* 1 = 0.044137 loss)
I1204 23:36:14.234454 31619 solver.cpp:228] Iteration 3500, loss = 0.00526225
I1204 23:36:14.234472 31619 solver.cpp:244]     Train net output #0: loss = 0.00526207 (* 1 = 0.00526207 loss)
I1204 23:36:14.234480 31619 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I1204 23:36:15.782665 31619 solver.cpp:228] Iteration 3600, loss = 0.023249
I1204 23:36:15.782685 31619 solver.cpp:244]     Train net output #0: loss = 0.0232488 (* 1 = 0.0232488 loss)
I1204 23:36:15.782691 31619 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I1204 23:36:17.330057 31619 solver.cpp:228] Iteration 3700, loss = 0.0141596
I1204 23:36:17.330076 31619 solver.cpp:244]     Train net output #0: loss = 0.0141594 (* 1 = 0.0141594 loss)
I1204 23:36:17.330083 31619 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I1204 23:36:18.877406 31619 solver.cpp:228] Iteration 3800, loss = 0.0127283
I1204 23:36:18.877439 31619 solver.cpp:244]     Train net output #0: loss = 0.0127281 (* 1 = 0.0127281 loss)
I1204 23:36:18.877445 31619 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I1204 23:36:20.431305 31619 solver.cpp:228] Iteration 3900, loss = 0.0224668
I1204 23:36:20.431339 31619 solver.cpp:244]     Train net output #0: loss = 0.0224666 (* 1 = 0.0224666 loss)
I1204 23:36:20.431346 31619 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I1204 23:36:21.964201 31619 solver.cpp:337] Iteration 4000, Testing net (#0)
I1204 23:36:23.059288 31619 solver.cpp:404]     Test net output #0: accuracy = 0.989
I1204 23:36:23.059309 31619 solver.cpp:404]     Test net output #1: loss = 0.0322834 (* 1 = 0.0322834 loss)
I1204 23:36:23.068681 31619 solver.cpp:228] Iteration 4000, loss = 0.0199571
I1204 23:36:23.068698 31619 solver.cpp:244]     Train net output #0: loss = 0.0199569 (* 1 = 0.0199569 loss)
I1204 23:36:23.068704 31619 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I1204 23:36:24.615687 31619 solver.cpp:228] Iteration 4100, loss = 0.0239632
I1204 23:36:24.615713 31619 solver.cpp:244]     Train net output #0: loss = 0.023963 (* 1 = 0.023963 loss)
I1204 23:36:24.615720 31619 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I1204 23:36:26.163374 31619 solver.cpp:228] Iteration 4200, loss = 0.0101926
I1204 23:36:26.163394 31619 solver.cpp:244]     Train net output #0: loss = 0.0101924 (* 1 = 0.0101924 loss)
I1204 23:36:26.163401 31619 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I1204 23:36:27.711343 31619 solver.cpp:228] Iteration 4300, loss = 0.0353423
I1204 23:36:27.711361 31619 solver.cpp:244]     Train net output #0: loss = 0.0353422 (* 1 = 0.0353422 loss)
I1204 23:36:27.711367 31619 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I1204 23:36:29.259240 31619 solver.cpp:228] Iteration 4400, loss = 0.0208219
I1204 23:36:29.259264 31619 solver.cpp:244]     Train net output #0: loss = 0.0208217 (* 1 = 0.0208217 loss)
I1204 23:36:29.259270 31619 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I1204 23:36:30.791527 31619 solver.cpp:337] Iteration 4500, Testing net (#0)
I1204 23:36:31.885685 31619 solver.cpp:404]     Test net output #0: accuracy = 0.988
I1204 23:36:31.885718 31619 solver.cpp:404]     Test net output #1: loss = 0.0368274 (* 1 = 0.0368274 loss)
I1204 23:36:31.894947 31619 solver.cpp:228] Iteration 4500, loss = 0.00718055
I1204 23:36:31.894975 31619 solver.cpp:244]     Train net output #0: loss = 0.00718036 (* 1 = 0.00718036 loss)
I1204 23:36:31.894982 31619 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I1204 23:36:33.441627 31619 solver.cpp:228] Iteration 4600, loss = 0.0116887
I1204 23:36:33.441645 31619 solver.cpp:244]     Train net output #0: loss = 0.0116885 (* 1 = 0.0116885 loss)
I1204 23:36:33.441669 31619 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I1204 23:36:34.990448 31619 solver.cpp:228] Iteration 4700, loss = 0.00507465
I1204 23:36:34.990471 31619 solver.cpp:244]     Train net output #0: loss = 0.00507447 (* 1 = 0.00507447 loss)
I1204 23:36:34.990478 31619 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I1204 23:36:36.539655 31619 solver.cpp:228] Iteration 4800, loss = 0.0125952
I1204 23:36:36.539675 31619 solver.cpp:244]     Train net output #0: loss = 0.0125951 (* 1 = 0.0125951 loss)
I1204 23:36:36.539680 31619 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I1204 23:36:38.086326 31619 solver.cpp:228] Iteration 4900, loss = 0.0126621
I1204 23:36:38.086350 31619 solver.cpp:244]     Train net output #0: loss = 0.0126619 (* 1 = 0.0126619 loss)
I1204 23:36:38.086356 31619 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I1204 23:36:39.619675 31619 solver.cpp:454] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I1204 23:36:39.633726 31619 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I1204 23:36:39.636528 31619 solver.cpp:337] Iteration 5000, Testing net (#0)
I1204 23:36:40.725275 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9892
I1204 23:36:40.725312 31619 solver.cpp:404]     Test net output #1: loss = 0.0315375 (* 1 = 0.0315375 loss)
I1204 23:36:40.734755 31619 solver.cpp:228] Iteration 5000, loss = 0.0409451
I1204 23:36:40.734783 31619 solver.cpp:244]     Train net output #0: loss = 0.040945 (* 1 = 0.040945 loss)
I1204 23:36:40.734792 31619 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I1204 23:36:42.283156 31619 solver.cpp:228] Iteration 5100, loss = 0.0171382
I1204 23:36:42.283263 31619 solver.cpp:244]     Train net output #0: loss = 0.0171381 (* 1 = 0.0171381 loss)
I1204 23:36:42.283272 31619 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I1204 23:36:43.831527 31619 solver.cpp:228] Iteration 5200, loss = 0.00830573
I1204 23:36:43.831547 31619 solver.cpp:244]     Train net output #0: loss = 0.00830558 (* 1 = 0.00830558 loss)
I1204 23:36:43.831552 31619 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I1204 23:36:45.379529 31619 solver.cpp:228] Iteration 5300, loss = 0.00309514
I1204 23:36:45.379559 31619 solver.cpp:244]     Train net output #0: loss = 0.00309501 (* 1 = 0.00309501 loss)
I1204 23:36:45.379565 31619 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I1204 23:36:46.927784 31619 solver.cpp:228] Iteration 5400, loss = 0.00544054
I1204 23:36:46.927805 31619 solver.cpp:244]     Train net output #0: loss = 0.0054404 (* 1 = 0.0054404 loss)
I1204 23:36:46.927811 31619 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I1204 23:36:48.460264 31619 solver.cpp:337] Iteration 5500, Testing net (#0)
I1204 23:36:49.555147 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9894
I1204 23:36:49.555171 31619 solver.cpp:404]     Test net output #1: loss = 0.0323454 (* 1 = 0.0323454 loss)
I1204 23:36:49.564380 31619 solver.cpp:228] Iteration 5500, loss = 0.00879394
I1204 23:36:49.564398 31619 solver.cpp:244]     Train net output #0: loss = 0.0087938 (* 1 = 0.0087938 loss)
I1204 23:36:49.564404 31619 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I1204 23:36:51.113037 31619 solver.cpp:228] Iteration 5600, loss = 0.000940685
I1204 23:36:51.113075 31619 solver.cpp:244]     Train net output #0: loss = 0.00094054 (* 1 = 0.00094054 loss)
I1204 23:36:51.113081 31619 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I1204 23:36:52.660986 31619 solver.cpp:228] Iteration 5700, loss = 0.00355784
I1204 23:36:52.661007 31619 solver.cpp:244]     Train net output #0: loss = 0.00355769 (* 1 = 0.00355769 loss)
I1204 23:36:52.661013 31619 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I1204 23:36:54.208933 31619 solver.cpp:228] Iteration 5800, loss = 0.0233412
I1204 23:36:54.208961 31619 solver.cpp:244]     Train net output #0: loss = 0.023341 (* 1 = 0.023341 loss)
I1204 23:36:54.208967 31619 sgd_solver.cpp:106] Iteration 5800, lr = 0.0070959
I1204 23:36:55.758096 31619 solver.cpp:228] Iteration 5900, loss = 0.00365275
I1204 23:36:55.758119 31619 solver.cpp:244]     Train net output #0: loss = 0.0036526 (* 1 = 0.0036526 loss)
I1204 23:36:55.758126 31619 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I1204 23:36:57.292572 31619 solver.cpp:337] Iteration 6000, Testing net (#0)
I1204 23:36:58.371148 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9905
I1204 23:36:58.371196 31619 solver.cpp:404]     Test net output #1: loss = 0.0280797 (* 1 = 0.0280797 loss)
I1204 23:36:58.381023 31619 solver.cpp:228] Iteration 6000, loss = 0.00269486
I1204 23:36:58.381053 31619 solver.cpp:244]     Train net output #0: loss = 0.0026947 (* 1 = 0.0026947 loss)
I1204 23:36:58.381063 31619 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I1204 23:36:59.929569 31619 solver.cpp:228] Iteration 6100, loss = 0.00297922
I1204 23:36:59.929621 31619 solver.cpp:244]     Train net output #0: loss = 0.00297907 (* 1 = 0.00297907 loss)
I1204 23:36:59.929633 31619 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I1204 23:37:01.466243 31619 solver.cpp:228] Iteration 6200, loss = 0.00799238
I1204 23:37:01.466289 31619 solver.cpp:244]     Train net output #0: loss = 0.00799223 (* 1 = 0.00799223 loss)
I1204 23:37:01.466297 31619 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I1204 23:37:03.017925 31619 solver.cpp:228] Iteration 6300, loss = 0.00689291
I1204 23:37:03.017964 31619 solver.cpp:244]     Train net output #0: loss = 0.00689277 (* 1 = 0.00689277 loss)
I1204 23:37:03.017972 31619 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I1204 23:37:04.565536 31619 solver.cpp:228] Iteration 6400, loss = 0.00808684
I1204 23:37:04.565577 31619 solver.cpp:244]     Train net output #0: loss = 0.00808671 (* 1 = 0.00808671 loss)
I1204 23:37:04.565608 31619 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I1204 23:37:06.097882 31619 solver.cpp:337] Iteration 6500, Testing net (#0)
I1204 23:37:07.189887 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9903
I1204 23:37:07.189921 31619 solver.cpp:404]     Test net output #1: loss = 0.0310969 (* 1 = 0.0310969 loss)
I1204 23:37:07.199790 31619 solver.cpp:228] Iteration 6500, loss = 0.00846869
I1204 23:37:07.199820 31619 solver.cpp:244]     Train net output #0: loss = 0.00846857 (* 1 = 0.00846857 loss)
I1204 23:37:07.199832 31619 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I1204 23:37:08.748260 31619 solver.cpp:228] Iteration 6600, loss = 0.0223323
I1204 23:37:08.748288 31619 solver.cpp:244]     Train net output #0: loss = 0.0223322 (* 1 = 0.0223322 loss)
I1204 23:37:08.748296 31619 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I1204 23:37:10.296800 31619 solver.cpp:228] Iteration 6700, loss = 0.0101587
I1204 23:37:10.296829 31619 solver.cpp:244]     Train net output #0: loss = 0.0101586 (* 1 = 0.0101586 loss)
I1204 23:37:10.296838 31619 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I1204 23:37:11.843631 31619 solver.cpp:228] Iteration 6800, loss = 0.00180029
I1204 23:37:11.843653 31619 solver.cpp:244]     Train net output #0: loss = 0.00180016 (* 1 = 0.00180016 loss)
I1204 23:37:11.843660 31619 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I1204 23:37:13.391017 31619 solver.cpp:228] Iteration 6900, loss = 0.00504215
I1204 23:37:13.391146 31619 solver.cpp:244]     Train net output #0: loss = 0.00504203 (* 1 = 0.00504203 loss)
I1204 23:37:13.391156 31619 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I1204 23:37:14.924000 31619 solver.cpp:337] Iteration 7000, Testing net (#0)
I1204 23:37:16.015590 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9893
I1204 23:37:16.015627 31619 solver.cpp:404]     Test net output #1: loss = 0.0304782 (* 1 = 0.0304782 loss)
I1204 23:37:16.025638 31619 solver.cpp:228] Iteration 7000, loss = 0.00928333
I1204 23:37:16.025672 31619 solver.cpp:244]     Train net output #0: loss = 0.00928321 (* 1 = 0.00928321 loss)
I1204 23:37:16.025681 31619 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I1204 23:37:17.574378 31619 solver.cpp:228] Iteration 7100, loss = 0.017896
I1204 23:37:17.574412 31619 solver.cpp:244]     Train net output #0: loss = 0.0178959 (* 1 = 0.0178959 loss)
I1204 23:37:17.574419 31619 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I1204 23:37:19.121597 31619 solver.cpp:228] Iteration 7200, loss = 0.00799754
I1204 23:37:19.121625 31619 solver.cpp:244]     Train net output #0: loss = 0.00799742 (* 1 = 0.00799742 loss)
I1204 23:37:19.121632 31619 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I1204 23:37:20.669934 31619 solver.cpp:228] Iteration 7300, loss = 0.0236198
I1204 23:37:20.669970 31619 solver.cpp:244]     Train net output #0: loss = 0.0236197 (* 1 = 0.0236197 loss)
I1204 23:37:20.669977 31619 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I1204 23:37:22.219033 31619 solver.cpp:228] Iteration 7400, loss = 0.00922398
I1204 23:37:22.219054 31619 solver.cpp:244]     Train net output #0: loss = 0.00922386 (* 1 = 0.00922386 loss)
I1204 23:37:22.219061 31619 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I1204 23:37:23.751168 31619 solver.cpp:337] Iteration 7500, Testing net (#0)
I1204 23:37:24.843722 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9892
I1204 23:37:24.843750 31619 solver.cpp:404]     Test net output #1: loss = 0.0325937 (* 1 = 0.0325937 loss)
I1204 23:37:24.853441 31619 solver.cpp:228] Iteration 7500, loss = 0.00205019
I1204 23:37:24.853461 31619 solver.cpp:244]     Train net output #0: loss = 0.00205007 (* 1 = 0.00205007 loss)
I1204 23:37:24.853468 31619 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I1204 23:37:26.402153 31619 solver.cpp:228] Iteration 7600, loss = 0.00590449
I1204 23:37:26.402174 31619 solver.cpp:244]     Train net output #0: loss = 0.00590438 (* 1 = 0.00590438 loss)
I1204 23:37:26.402181 31619 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I1204 23:37:27.949836 31619 solver.cpp:228] Iteration 7700, loss = 0.0289034
I1204 23:37:27.949887 31619 solver.cpp:244]     Train net output #0: loss = 0.0289033 (* 1 = 0.0289033 loss)
I1204 23:37:27.949894 31619 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I1204 23:37:29.497236 31619 solver.cpp:228] Iteration 7800, loss = 0.00543382
I1204 23:37:29.497282 31619 solver.cpp:244]     Train net output #0: loss = 0.00543371 (* 1 = 0.00543371 loss)
I1204 23:37:29.497290 31619 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I1204 23:37:31.045461 31619 solver.cpp:228] Iteration 7900, loss = 0.00317847
I1204 23:37:31.045500 31619 solver.cpp:244]     Train net output #0: loss = 0.00317837 (* 1 = 0.00317837 loss)
I1204 23:37:31.045507 31619 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I1204 23:37:32.578752 31619 solver.cpp:337] Iteration 8000, Testing net (#0)
I1204 23:37:33.670977 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9899
I1204 23:37:33.671020 31619 solver.cpp:404]     Test net output #1: loss = 0.0288867 (* 1 = 0.0288867 loss)
I1204 23:37:33.680835 31619 solver.cpp:228] Iteration 8000, loss = 0.0049488
I1204 23:37:33.680866 31619 solver.cpp:244]     Train net output #0: loss = 0.0049487 (* 1 = 0.0049487 loss)
I1204 23:37:33.680872 31619 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I1204 23:37:35.231174 31619 solver.cpp:228] Iteration 8100, loss = 0.00627718
I1204 23:37:35.231217 31619 solver.cpp:244]     Train net output #0: loss = 0.00627708 (* 1 = 0.00627708 loss)
I1204 23:37:35.231247 31619 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I1204 23:37:36.780755 31619 solver.cpp:228] Iteration 8200, loss = 0.00851385
I1204 23:37:36.780777 31619 solver.cpp:244]     Train net output #0: loss = 0.00851376 (* 1 = 0.00851376 loss)
I1204 23:37:36.780784 31619 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I1204 23:37:38.330274 31619 solver.cpp:228] Iteration 8300, loss = 0.0187675
I1204 23:37:38.330320 31619 solver.cpp:244]     Train net output #0: loss = 0.0187674 (* 1 = 0.0187674 loss)
I1204 23:37:38.330328 31619 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I1204 23:37:39.877478 31619 solver.cpp:228] Iteration 8400, loss = 0.00734812
I1204 23:37:39.877522 31619 solver.cpp:244]     Train net output #0: loss = 0.00734802 (* 1 = 0.00734802 loss)
I1204 23:37:39.877529 31619 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I1204 23:37:41.407582 31619 solver.cpp:337] Iteration 8500, Testing net (#0)
I1204 23:37:42.497156 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9902
I1204 23:37:42.497195 31619 solver.cpp:404]     Test net output #1: loss = 0.0292049 (* 1 = 0.0292049 loss)
I1204 23:37:42.506885 31619 solver.cpp:228] Iteration 8500, loss = 0.00682862
I1204 23:37:42.506916 31619 solver.cpp:244]     Train net output #0: loss = 0.00682853 (* 1 = 0.00682853 loss)
I1204 23:37:42.506922 31619 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I1204 23:37:44.055660 31619 solver.cpp:228] Iteration 8600, loss = 0.000662259
I1204 23:37:44.055841 31619 solver.cpp:244]     Train net output #0: loss = 0.000662174 (* 1 = 0.000662174 loss)
I1204 23:37:44.055852 31619 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I1204 23:37:45.603407 31619 solver.cpp:228] Iteration 8700, loss = 0.00328982
I1204 23:37:45.603430 31619 solver.cpp:244]     Train net output #0: loss = 0.00328973 (* 1 = 0.00328973 loss)
I1204 23:37:45.603437 31619 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I1204 23:37:47.150214 31619 solver.cpp:228] Iteration 8800, loss = 0.00186552
I1204 23:37:47.150235 31619 solver.cpp:244]     Train net output #0: loss = 0.00186543 (* 1 = 0.00186543 loss)
I1204 23:37:47.150243 31619 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I1204 23:37:48.697968 31619 solver.cpp:228] Iteration 8900, loss = 0.000822824
I1204 23:37:48.697988 31619 solver.cpp:244]     Train net output #0: loss = 0.000822746 (* 1 = 0.000822746 loss)
I1204 23:37:48.697995 31619 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I1204 23:37:50.231428 31619 solver.cpp:337] Iteration 9000, Testing net (#0)
I1204 23:37:51.323535 31619 solver.cpp:404]     Test net output #0: accuracy = 0.9892
I1204 23:37:51.323585 31619 solver.cpp:404]     Test net output #1: loss = 0.0309362 (* 1 = 0.0309362 loss)
I1204 23:37:51.333539 31619 solver.cpp:228] Iteration 9000, loss = 0.0168241
I1204 23:37:51.333569 31619 solver.cpp:244]     Train net output #0: loss = 0.016824 (* 1 = 0.016824 loss)
I1204 23:37:51.333576 31619 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I1204 23:37:52.881729 31619 solver.cpp:228] Iteration 9100, loss = 0.00946239
I1204 23:37:52.881765 31619 solver.cpp:244]     Train net output #0: loss = 0.00946232 (* 1 = 0.00946232 loss)
I1204 23:37:52.881773 31619 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I1204 23:37:54.424439 31619 solver.cpp:228] Iteration 9200, loss = 0.00246553
I1204 23:37:54.424469 31619 solver.cpp:244]     Train net output #0: loss = 0.00246547 (* 1 = 0.00246547 loss)
I1204 23:37:54.424475 31619 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
